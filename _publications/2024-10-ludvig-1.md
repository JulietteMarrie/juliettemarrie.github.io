---
title: "LUDVIG: Learning-free Uplifting of 2D Visual features to Gaussian Splatting scenes"
collection: publications
category: arxiv
permalink: /publication/2024-10-ludvig
venue: 'arXiv preprint'
excerpt: '*Juliette Marrie, Romain Menegaux, Michael Arbel, Diane Larlus, Julien Mairal*<br><br>This paper proposes an efficient, learning-free approach for transferring 2D visual representations into 3D Gaussian Splatting scenes.'
date: 2024-10-21
media:
  - type: image
    src: /files/ludvig.png
    caption: "Illustration of the inverse and forward rendering between 2D visual features (produced by DINOv2) and a 3D Gaussian Splatting scene. In the inverse rendering (or uplifting) phase, features are created for each 3D Gaussian by aggregating coarse 2D features over all viewing directions. For forward rendering, the 3D features are projected on any given viewing direction as in regular Gaussian Splatting."
  - type: video
    src: /files/diffusion.mp4
    caption: "3D graph diffusion for foreground/background segmentation. The 3D mask spreads to neighboring Gaussians with similar DINOv2 features."
    format: mp4
  - type: video
    src: /files/figurines.mp4
    format: mp4
  - type: video
    src: /files/teatime.mp4
    format: mp4
    caption: "3D DINOv2 features (left), CLIP features (middle) and CLIP relevancy with text prompts (right)."
paperurl: 'https://arxiv.org/abs/2410.14462'
---

*Juliette Marrie, Romain Menegaux, Michael Arbel, Diane Larlus, Julien Mairal*

We address the problem of extending the capabilities of vision foundation models such as DINO, SAM, and CLIP, to 3D tasks. Specifically, we introduce a novel method to uplift 2D image features into 3D Gaussian Splatting scenes. Unlike traditional approaches that rely on minimizing a reconstruction loss, our method employs a simpler and more efficient feature aggregation technique, augmented by a graph diffusion mechanism. Graph diffusion enriches features from a given model, such as CLIP, by leveraging 3D geometry and pairwise similarities induced by another strong model such as DINOv2. Our approach achieves performance comparable to the state of the art on multiple downstream tasks while delivering significant speed-ups. Notably, we obtain competitive segmentation results using generic DINOv2 features, despite DINOv2 not being trained on millions of annotated segmentation masks like SAM. When applied to CLIP features, our method demonstrates strong performance in open-vocabulary object detection tasks, highlighting the versatility of our approach. 


<div style="text-align: left; margin-top: 20px;">
  {% if page.media %}
    {% for media in page.media %}
      <figure style="margin-bottom: 20px;">
        {% if media.type == "image" %}
          <img src="{{ media.src }}" alt="Media content" style="max-width: 100%; margin-bottom: 10px;">
        {% elsif media.type == "video" %}
          <video controls loop style="max-width: 100%; margin-bottom: 10px;">
            <source src="{{ media.src }}" type="video/mp4">
            Your browser does not support the video tag.
          </video>
        {% endif %}
        {% if media.caption %}
          <figcaption style="font-size: 15px; font-style: italic; text-align: left;">
            {{ media.caption }}
          </figcaption>
        {% endif %}
      </figure>
    {% endfor %}
  {% endif %}
</div>

{% if page.paperurl %}
  <p style="text-align: center;"><strong><a href="{{ page.paperurl }}" target="_blank">Read the full paper</a></strong></p>
{% endif %}
